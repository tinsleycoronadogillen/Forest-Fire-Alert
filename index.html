<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Early Fire & Smoke Detection – Teachable Machine</title>

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700&display=swap" rel="stylesheet">

    <style>
        body {
            font-family: "Poppins", sans-serif;
            margin: 0;
            background: linear-gradient(135deg, #f7f7f8 0%, #ececec 100%);
            color: #222;
        }

        header {
            background: linear-gradient(135deg, #d32f2f, #b71c1c);
            color: white;
            padding: 40px;
            text-align: center;
            box-shadow: 0 4px 12px rgba(0,0,0,0.3);
        }

        header h1 {
            font-size: 2.5rem;
            margin: 0;
        }

        main {
            max-width: 1000px;
            margin: auto;
            padding: 20px;
        }

        .card {
            background: white;
            padding: 30px;
            margin-top: 25px;
            border-radius: 12px;
            box-shadow: 0 4px 18px rgba(0,0,0,0.12);
            transition: 0.3s ease;
        }
        .card:hover {
            transform: translateY(-3px);
        }

        h2 {
            color: #b71c1c;
            margin-top: 0;
        }

        button {
            background: #d32f2f;
            color: white;
            border: none;
            padding: 12px 22px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 16px;
            transition: 0.25s;
            margin-right: 10px;
        }
        button:hover {
            background: #b71c1c;
            transform: scale(1.05);
        }

        #webcam-container {
            margin-top: 20px;
            display: flex;
            justify-content: center;
        }

        #label-container {
            margin-top: 20px;
            font-size: 1.1rem;
        }

        .upload-area {
            margin-top: 25px;
            padding: 25px;
            border: 2px dashed #ccc;
            border-radius: 12px;
            background: #fafafa;
            text-align: center;
            transition: 0.2s;
        }
        .upload-area:hover {
            border-color: #d32f2f;
            background: #fff3f3;
        }

        img#uploaded-image {
            max-width: 350px;
            margin-top: 20px;
            border-radius: 10px;
            display: none;
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        }

        #loadingMessage {
            display: none;
            color: #b71c1c;
            font-weight: bold;
            margin-top: 10px;
        }
    </style>
</head>

<body>
<header>
    <h1>Early Fire & Smoke Detection System</h1>
    <p>AI-powered fire hazard detection using Google Teachable Machine</p>
</header>

<main>

    <!-- ABOUT PROJECT -->
    <div class="card">
        <h2>About This Project</h2>
        <p><strong>Project Title:</strong> Early Fire/Smoke Detection</p>
        <p>
            This AI-powered system helps detect early signs of fire in environments where traditional smoke detectors 
            cannot easily be installed—such as forests, wildlife areas, and other remote locations. The system recognizes:
        </p>
        <ul>
            <li><strong>No Fire</strong></li>
            <li><strong>Smoke</strong></li>
            <li><strong>Fire</strong></li>
        </ul>
        <p>
            Organizations such as forestry services, national parks, and environmental monitoring agencies can use it 
            to reduce wildfire risks through early intervention.
        </p>
    </div>

    <!-- HOW IT WORKS -->
    <div class="card">
        <h2>How the AI Model Works</h2>
        <p>
            This website uses Google’s <strong>Teachable Machine</strong>, which allows users to create an AI model without coding.
            After uploading images of Fire, Smoke, and No Fire, the system learns the visual differences using machine learning.
            The trained model runs directly in your browser using TensorFlow.js—no data is uploaded.
        </p>
    </div>

    <!-- INSTRUCTIONS -->
    <div class="card">
        <h2>Instructions</h2>
        <ol>
            <li>Click <strong>Start Webcam</strong> to analyze live video.</li>
            <li>Or upload an image using the <strong>Upload Image</strong> box.</li>
            <li>The prediction results appear below the image or webcam.</li>
            <li>High probabilities of “Smoke” or “Fire” would trigger alerts in a full deployment.</li>
        </ol>
    </div>

    <!-- MODEL INTERFACE -->
    <div class="card">
        <h2>Fire/Smoke Detection Model</h2>

        <button onclick="init()">Start Webcam</button>
        <button onclick="stopWebcam()">Stop Webcam</button>

        <div id="webcam-container"></div>
        <div id="label-container"></div>

        <p id="loadingMessage">Loading model, please wait...</p>

        <div class="upload-area">
            <p><strong>Or upload an image:</strong></p>
            <input type="file" accept="image/*" onchange="handleImageUpload(event)">
            <img id="uploaded-image" />
        </div>
    </div>

</main>

<!-- SCRIPTS -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>

<script>
    const URL = "./my_model/";
    let model, webcam, labelContainer, maxPredictions;
    let webcamRunning = false;

    async function loadModel() {
        if (model) return model; // If already loaded, reuse it

        document.getElementById("loadingMessage").style.display = "block";

        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        document.getElementById("loadingMessage").style.display = "none";
        return model;
    }

    async function init() {
        await loadModel();

        webcam = new tmImage.Webcam(300, 300, true);
        await webcam.setup();
        await webcam.play();
        webcamRunning = true;

        document.getElementById("webcam-container").innerHTML = "";
        document.getElementById("webcam-container").appendChild(webcam.canvas);

        labelContainer = document.getElementById("label-container");
        labelContainer.innerHTML = "";
        for (let i = 0; i < maxPredictions; i++) {
            labelContainer.appendChild(document.createElement("div"));
        }

        window.requestAnimationFrame(loop);
    }

    function stopWebcam() {
        if (webcam && webcam.webcam) {
            webcam.stop();
            webcamRunning = false;
        }
    }

    async function loop() {
        if (!webcamRunning) return;
        webcam.update();
        await predict(webcam.canvas);
        window.requestAnimationFrame(loop);
    }

    // IMAGE UPLOAD
    async function handleImageUpload(event) {
        stopWebcam();
        await loadModel();

        const imgFile = event.target.files[0];
        const imgElement = document.getElementById("uploaded-image");

        imgElement.src = URL.createObjectURL(imgFile);
        imgElement.style.display = "block";

        imgElement.onload = async () => {
            await predict(imgElement);
        };
    }

    // PREDICTION FUNCTION
    async function predict(input) {
        const prediction = await model.predict(input);

        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction = 
                `${prediction[i].className}: ${prediction[i].probability.toFixed(2)}`;
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
    }
</script>

</body>
</html>
